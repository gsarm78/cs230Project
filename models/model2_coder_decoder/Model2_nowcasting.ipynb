{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model2_nowcasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsarm78/cs230Project/blob/master/models/model2_coder_decoder/Model2_nowcasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSL5SRg5P_Aa",
        "colab_type": "code",
        "outputId": "e78f1472-bc4b-4d6e-c1d3-e52ff265ea51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!git clone https://github.com/gsarm78/cs230Project.git\n",
        "print(\"[INFO] Git repo cloned\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cs230Project' already exists and is not an empty directory.\n",
            "[INFO] Git repo cloned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyHbfK8vQBOq",
        "colab_type": "code",
        "outputId": "c396f8a7-7e76-4a14-af52-51a28fc73226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "import time\n",
        "import pylab as plt\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow.compat.v1.keras as keras\n",
        "from tensorflow.compat.v1.keras.models import Sequential, Model, load_model, model_from_json\n",
        "from tensorflow.compat.v1.keras.layers import Input, Add, Conv2D, Conv3D, Conv2DTranspose, Concatenate, TimeDistributed, BatchNormalization, ConvLSTM2D, BatchNormalization, LeakyReLU, MaxPooling2D, UpSampling2D, TimeDistributed, MaxPooling2D, UpSampling2D, Lambda, Dropout, Flatten, Reshape\n",
        "from tensorflow.compat.v1.keras.optimizers import *\n",
        "from tensorflow.compat.v1.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.compat.v1.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.compat.v1.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.DEBUG)\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  ### NO WARNINGS!\n",
        "tf.__version__\n",
        "print(\"[INFO] Imports loaded.\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] Imports loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l70MRFFHQHcA",
        "colab_type": "code",
        "outputId": "0188fd91-e617-4379-b2a7-7f1f691ab0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# DATA LOADING AND PROCESSING INTO NUMPY ARRAY\n",
        "\n",
        "IMAGE_PATH = '/content/cs230Project/samples'\n",
        "\n",
        "\n",
        "WIDTH = 64\n",
        "HEIGHT = 64\n",
        "IMG_SEQUENCE = np.array([])\n",
        "INPUT_SEQUENCE = np.array([])\n",
        "NEXT_SEQUENCE = np.array([])\n",
        "NUMBER = 0\n",
        "\n",
        "def image_initialize(image):\n",
        "    picture = Image.open(image)\n",
        "    #picture = picture.crop((243, 176, 1428, 1280))\n",
        "    picture = picture.resize((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
        "    picture = picture.convert('L')\n",
        "    data = np.array(picture.getdata()).reshape(WIDTH, HEIGHT, 1)\n",
        "    return data\n",
        "\n",
        "for file in os.listdir(IMAGE_PATH):\n",
        "    image_array = image_initialize(os.path.join(IMAGE_PATH, file))\n",
        "    IMG_SEQUENCE = np.append(IMG_SEQUENCE, image_array)\n",
        "    NUMBER += 1\n",
        "\n",
        "IMG_SEQUENCE = IMG_SEQUENCE.reshape(NUMBER, WIDTH * HEIGHT)\n",
        "print(IMG_SEQUENCE.shape)\n",
        "\n",
        "for i in IMG_SEQUENCE:\n",
        "    for j in range(int(len(i))):\n",
        "        if i[j] < 50:\n",
        "            i[j] = 0\n",
        "\n",
        "#np.savez('/content/cs230Project/data/images_sequence_array.npz', sequence_array=IMG_SEQUENCE) # test\n",
        "np.savez('/content/cs230Project/data/images_sequence_array.npz', sequence_array=IMG_SEQUENCE) # original\n",
        "print('[INFO] Data (images) saved as numpy compressed array')\n",
        "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 4096)\n",
            "[INFO] Data (images) saved as numpy compressed array\n",
            "2020-03-15 18:56:55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPRrWJ1nUCe5",
        "colab_type": "code",
        "outputId": "5f44bd37-5562-4648-88b6-32e9c162282e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# LOADING OF NUMPY ARRAY INTO SEQUENCES #\n",
        "#########################################\n",
        "\n",
        "FRAMES = 20 #frames to process\n",
        "\n",
        "IMG_SEQUENCE = np.load('/content/cs230Project/data/images_sequence_array.npz')['sequence_array']  # load array\n",
        "print('[INFO] Image Sequence Data loaded.')\n",
        "#print('[INFO]', IMG_SEQUENCE.shaoe)\n",
        "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
        "\n",
        "\n",
        "\n",
        "# Number of input images in the sequence\n",
        "NUMBER = len(IMG_SEQUENCE)\n",
        "\n",
        "IMG_SEQUENCE = IMG_SEQUENCE.reshape(NUMBER, WIDTH, HEIGHT, 1)\n",
        "print(IMG_SEQUENCE.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Image Sequence Data loaded.\n",
            "2020-03-15 18:56:58\n",
            "(80, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkgKGeRUyaU",
        "colab_type": "code",
        "outputId": "cf2a7f7a-7b0b-4fb9-9362-6b7fc1ac376d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "INPUT_SEQUENCE = np.zeros((NUMBER-FRAMES, FRAMES, WIDTH, HEIGHT, 1), dtype=float)\n",
        "NEXT_SEQUENCE = np.zeros((NUMBER-FRAMES, FRAMES, WIDTH, HEIGHT, 1), dtype=float)\n",
        "\n",
        "\n",
        "\n",
        "#######\n",
        "# report pixel means and standard deviations\n",
        "#print('[INFO] IMG_SEQUENCE Statistics train=%.3f (%.3f)' % (IMG_SEQUENCE.mean(), IMG_SEQUENCE.std()))\n",
        "#mean substraction\n",
        "#IMG_SEQUENCE -=np.mean(IMG_SEQUENCE)\n",
        "#print('[INFO] IMG_SEQUENCE after Zero centred train=%.3f (%.3f)' % (IMG_SEQUENCE.mean(), IMG_SEQUENCE.std()))\n",
        "#IMG_SEQUENCE /= np.std(IMG_SEQUENCE)\n",
        "#print('normalised train=%.3f (%.3f)' % (IMG_SEQUENCE.mean(), IMG_SEQUENCE.std()))\n",
        "########\n",
        "\n",
        "for i in range(FRAMES):\n",
        "    #print(i)\n",
        "    INPUT_SEQUENCE[:, i, :, :, :] = IMG_SEQUENCE[i:i+NUMBER-FRAMES]\n",
        "    NEXT_SEQUENCE[:, i, :, :, :] = IMG_SEQUENCE[i+1:i+NUMBER-FRAMES+1]\n",
        "\n",
        "print('[INFO] InputSeq Statistics=%.3f (%.3f)' % (INPUT_SEQUENCE.mean(), INPUT_SEQUENCE.std()))\n",
        "print('[INFO] NextSeq Statistics=%.3f (%.3f)' % (NEXT_SEQUENCE.mean(), NEXT_SEQUENCE.std()))\n",
        "\n",
        "print(INPUT_SEQUENCE.shape)\n",
        "print(NEXT_SEQUENCE.shape) \n",
        "print(\"[INFO] Input sequence ready\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] InputSeq Statistics=8.954 (31.579)\n",
            "[INFO] NextSeq Statistics=8.952 (31.577)\n",
            "(60, 20, 64, 64, 1)\n",
            "(60, 20, 64, 64, 1)\n",
            "[INFO] Input sequence ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1tsYtMJQNfZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow.compat.v1.keras as keras\n",
        "\n",
        "from tensorflow.compat.v1.keras.models import Model, load_model\n",
        "from tensorflow.compat.v1.keras.layers import Input, Conv2D, ConvLSTM2D, Dense, Conv2DTranspose, SeparableConv2D\n",
        "from tensorflow.compat.v1.keras.layers import MaxPooling2D, UpSampling2D, Lambda, Dropout, Flatten, Reshape\n",
        "from tensorflow.compat.v1.keras.layers import TimeDistributed, BatchNormalization, Concatenate\n",
        "from tensorflow.compat.v1.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "tf.__version__\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJ-7CY1Qhdd",
        "colab_type": "code",
        "outputId": "c8d75335-e0e7-483d-9442-df189341093a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Bring dataset in shape\n",
        "xs = INPUT_SEQUENCE\n",
        "xs = xs.astype(np.float32)\n",
        "xs = xs / np.max(xs)\n",
        "#xs = np.swapaxes(xs, 0, 1)  # swap frames and observations so [obs, frames, height, width, channels]\n",
        "#xs = np.expand_dims(xs, -1) #Add channel dimension\n",
        "print(f\"Dataset shape: {xs.shape}\")\n",
        "print('[INFO] InputSeq Statistics=%.3f (%.3f)' % (xs.mean(), xs.std()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape: (60, 20, 64, 64, 1)\n",
            "[INFO] InputSeq Statistics=0.042 (0.148)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_tDGeNQnmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Motion Diff Input for Motion Encoder\n",
        "def motion_diff(x):\n",
        "    seqLen = len(x[0])\n",
        "    return np.asarray([[x[n][i]-x[n][i-1] for i in range(1,seqLen)] for n in range(len(x))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1BsG7tFROn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "end = 50  #8000\n",
        "seqLen = 10\n",
        "x_dim, y_dim, c_dim = 64, 64, 1\n",
        "fs = (5,5)  # filter size for convolutional kernels\n",
        "nk = 128     # number of kernels for conv layers #48 \n",
        "nd = 2048    # number of neurons in dense layers #192"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZcwVnS2Rd99",
        "colab_type": "code",
        "outputId": "f772cabe-5881-4bd3-dee6-546f58039712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Inputs\n",
        "dtype='float32'\n",
        "contentInput = Input(shape=(x_dim, y_dim, c_dim), name='content_input', dtype=dtype)\n",
        "motionInput = Input(shape=(None, x_dim, y_dim, c_dim), name='motion_input', dtype=dtype)\n",
        "\n",
        "# Content Encoder\n",
        "x = Conv2D(nk, fs, activation='relu', padding='same', name='content_conv_1')(contentInput)\n",
        "x = Conv2D(nk, fs, activation='relu', padding='same', name='content_conv_new1')(x) #new\n",
        "x = MaxPooling2D((2,2), name='content_pool_1')(x)\n",
        "#x = BatchNormalization()(x) #new\n",
        "x = Conv2D(nk*2, fs, activation='relu', padding='same', name='content_conv_2')(x)\n",
        "x = Conv2D(nk*2, fs, activation='relu', padding='same', name='content_conv_new2')(x) #new\n",
        "x = MaxPooling2D((2,2), name='content_pool_2')(x)\n",
        "#x = Dropout(rate=0.5, name='dropout')(x)\n",
        "#x = BatchNormalization()(x)#new\n",
        "x = Conv2D(nk*4, fs, activation='relu', padding='same', name='content_conv_3')(x)\n",
        "x = Conv2D(nk*4, fs, activation='relu', padding='same', name='content_conv_new3')(x) #new\n",
        "x = Conv2D(nk*4, fs, activation='relu', padding='same', name='content_conv_new3-2')(x) #new\n",
        "contentEnc = MaxPooling2D((2,2), name='content_pool_3')(x)\n",
        "#x = BatchNormalization()(x)#new\n",
        "#x = Flatten()(x)\n",
        "#contentEnc = Dense(nd*4, activation='relu', name='content_latent')(x)\n",
        "\n",
        "# Motion Encoder\n",
        "# Layer 1\n",
        "tcnv1 = TimeDistributed(Conv2D(nk, (5,5), activation='relu', padding='same'), name='motion_conv_1')(motionInput) \n",
        "x = TimeDistributed(MaxPooling2D((2,2)), name='motion_pool_1')(tcnv1) #original (2,2)\n",
        "# Layer 2\n",
        "tcnv2 = TimeDistributed(Conv2D(nk, (5,5), activation='relu', padding='same'), name='motion_conv_2')(x)\n",
        "x = TimeDistributed(MaxPooling2D((2,2)), name='motion_pool_2')(tcnv2)\n",
        "# Layer 3\n",
        "tcnv3 = TimeDistributed(Conv2D(nk, (7,7), activation='relu', padding='same'), name='motion_conv_3')(x)\n",
        "x = TimeDistributed(MaxPooling2D((2,2)), name='motion_pool_3')(tcnv3)\n",
        "# Layer 4\n",
        "motionEnc = ConvLSTM2D(nk*8, (8,8), activation='relu', padding='same', return_sequences=False, dropout=0.4, recurrent_dropout=0.4, name='motion_lstm', dtype=dtype)(x)\n",
        "#x = Flatten()(x)\n",
        "#motionEnc = Dense(nd*4, activation='relu', name='motion_latent')(x) #relu #sigmoid before\n",
        "\n",
        "# Combination\n",
        "x = Concatenate(name='concat_layer')([contentEnc, motionEnc])  #contentEnc, motionEnc\n",
        "x = Conv2D(nk*4, (3, 3), activation='relu', padding='same', name='comb_conv_1')(x)\n",
        "x = Conv2D(nk*2, (3, 3), activation='relu', padding='same', name='comb_conv_new1')(x) #new\n",
        "combined = Conv2D(nk*4, (3, 3), activation='relu', padding='same', name='comb_conv_new1-2')(x)\n",
        "\n",
        "# Residuals\n",
        "res3 = Lambda(lambda x: x[:,-1])(tcnv3)\n",
        "res2 = Lambda(lambda x: x[:,-1])(tcnv2)\n",
        "res1 = Lambda(lambda x: x[:,-1])(tcnv1)\n",
        "\n",
        "# Decoder\n",
        "x = UpSampling2D((2,2), name='decoder_upsample_1')(combined)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_1')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_new1')(x) #new\n",
        "x = Conv2DTranspose(nk*2, fs, activation='relu', padding='same', name='decoder_conv_new1-2')(x) #new\n",
        "\n",
        "x = Concatenate()([x, res3]) #res3\n",
        "x = UpSampling2D((2,2), name='decoder_upsample_2')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_2')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_new2')(x) #new\n",
        "\n",
        "x = Concatenate()([x, res2])\n",
        "x = UpSampling2D((2,2), name='decoder_upsample_3')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_3')(x)\n",
        "x = Concatenate()([x, res1]) #res1\n",
        "#x = BatchNormalization()(x)\n",
        "predictions = Conv2DTranspose(1, fs, activation='tanh', padding='same', name='prediction')(x) #sigmoid original\n",
        "\n",
        "#custom loss function\n",
        "def weight_loss(y_true,y_pred):\n",
        "    pw = 2\n",
        "    ytrue = keras.backend.flatten(y_true)\n",
        "    ypred = keras.backend.flatten(y_pred)\n",
        "    return tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=ypred,targets=ytrue,pos_weight=pw))\n",
        "\n",
        "\n",
        "# Create and compile model\n",
        "model = Model(inputs= [contentInput, motionInput], outputs=predictions)\n",
        "\n",
        "optim = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "model.compile(loss='mse', optimizer=optim, metrics=[\"accuracy\"]) #mse \n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I56D38BRh20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualise Model Topology and save to file (model.png)\n",
        "#from keras.utils import plot_model\n",
        "#plot_model(model, show_shapes=True, to_file='/model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6BNVohsRkt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data\n",
        "train_x = [xs[:end,seqLen-2], motion_diff(xs[:end,:seqLen-1])]  #list\n",
        "\n",
        "# train_x = motion_diff(xs[:end,:seqLen-1])\n",
        "\n",
        "train_y = xs[:end,seqLen-1]\n",
        "\n",
        "val_x   = [xs[end:,seqLen-2], motion_diff(xs[end:,:seqLen-1])]\n",
        "\n",
        "# val_x   = motion_diff(xs[end:,:seqLen-1])\n",
        "\n",
        "val_y   = xs[end:,seqLen-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WZFupfBRoHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define Class to track performance (loss) hisrory\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, start_new_on_train_begin):\n",
        "        self.start_new_on_train_begin = start_new_on_train_begin\n",
        "        self.batches = []\n",
        "        self.epochs = {'train':[], 'val':[]}\n",
        "    \n",
        "    def on_train_begin(self, logs={}):\n",
        "        if self.start_new_on_train_begin:\n",
        "            self.batches = []\n",
        "            self.epochs = {'train':[], 'val':[]}\n",
        "\n",
        "    def copy_from(self, different_loss_history):\n",
        "        self.batches = different_loss_history.batches\n",
        "        self.epochs = different_loss_history.epochs\n",
        "            \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.batches.append(logs.get('loss'))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.epochs['train'].append(logs.get('loss'))\n",
        "        self.epochs['val'].append(logs.get('val_loss'))\n",
        "loss_history = LossHistory(start_new_on_train_begin=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md_PGixSRsha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "3a39f8b9-299a-48dc-c8cd-5cf2db3db44f"
      },
      "source": [
        "#Training Hyperparameters\n",
        "batch_size = 2\n",
        "n_epochs = 25\n",
        "\n",
        "history = model.fit(train_x, train_y, batch_size=batch_size, \n",
        "                    epochs=n_epochs, validation_data=(val_x, val_y),\n",
        "                    callbacks=[loss_history]) # Add shuffle=True"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 50 samples, validate on 10 samples\n",
            "Epoch 1/25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0bf6cb7cdaf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m history = model.fit(train_x, train_y, batch_size=batch_size, \n\u001b[1;32m      5\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=[loss_history]) # Add shuffle=True\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,8,1024,4096] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training/Adam/gradients/gradients/motion_lstm/while/split_1_grad/concat}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4ZxsCG8TiMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save model\n",
        "model.save('Model2_Nowcasting_(CoderDecoder_Arch).h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sa6I_4FX1bE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot Training Loss vs. Validation Loss\n",
        "plt.plot(loss_history.epochs['train'][2:], label='Training Loss')\n",
        "plt.plot(loss_history.epochs['val'][2:], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw8VdtImX6ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "performance_history = {\n",
        "    'batches':loss_history.batches,\n",
        "    'epochs':loss_history.epochs\n",
        "    }\n",
        "with open('model_loss_history.txt', 'w') as f:\n",
        "    print(performance_history, file=f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jme08yIX9eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment to \n",
        "# Load model from storage\n",
        "\n",
        "#model_dir = '/'\n",
        "#model = load_model(Path(model_dir, 'Model2_Nowcasting_(CoderDecoder_Arch).h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uoZZEyjYDRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_prediction(seq_idx, plot_gt=False, use_own_predictions=False, show_label=True):\n",
        "    for i, which in enumerate(seq_idx):\n",
        "\n",
        "        if show_label: print(f\"({i+1}) : {which}\")\n",
        "\n",
        "        input_length = 10 # length of input sequence\n",
        "        prediction_length = 10 # length of prediction\n",
        "        ground_truth = xs[which:which+1] # ground truth sequence\n",
        "\n",
        "\n",
        "        if use_own_predictions:\n",
        "            print(\"Use_own_prediction = True\")\n",
        "            pred = xs[which:which+1,input_length-1] # current frame, (1, 64, 64, 1)\n",
        "            print(pred.shape)\n",
        "            input_seq = ground_truth[:,0:input_length] # input sequence (first <inputLen> frames)   ,  (1, 10, 64, 64, 1)\n",
        "            print(input_seq.shape)\n",
        "            for i in range(input_length):\n",
        "                # Model predicts next frame\n",
        "                pred = model.predict([pred, motion_diff(input_seq)]) # return shape: (1, 64, 64, 1)\n",
        "                # Cut first frame from sequence\n",
        "                input_seq = np.squeeze(input_seq, axis=0)\n",
        "                input_seq = input_seq[1:]\n",
        "                # Append predicted frame to sequence\n",
        "                input_seq = np.append(input_seq, pred, axis=0)\n",
        "                input_seq = np.array([input_seq]) \n",
        "            predictions = input_seq\n",
        "        \n",
        "        else:\n",
        "            # Use ground truth in each time step as input\n",
        "            print(\"Use_own_prediction = False\")\n",
        "            print(\"Use Ground truth in each time step as input\")\n",
        "            predictions = []\n",
        "            for i in range(prediction_length):\n",
        "                input_seq = ground_truth[:, i:input_length+i]\n",
        "                prediction = model.predict([input_seq[:,-1], motion_diff(input_seq)])\n",
        "                predictions.append(prediction[0])\n",
        "            predictions = np.array([predictions])\n",
        "        \n",
        "        figures=(input_length*2, 1)\n",
        "        #figures=(input_length+prediction_length, 1)\n",
        "        \n",
        "        # Plot the ground truth sequence\n",
        "        if plot_gt:\n",
        "            fig,axs = plt.subplots(1, input_length+prediction_length, figsize=figures); cnt=0\n",
        "            for col in axs:\n",
        "                col.imshow(np.squeeze(ground_truth[0,cnt], axis=2))\n",
        "                col.axis('off')\n",
        "                cnt += 1   \n",
        "\n",
        "\n",
        "        # Plot the input and predicted sequence\n",
        "        fig,axs = plt.subplots(1, input_length+prediction_length, figsize=figures); cnt=0\n",
        "        for col in axs:\n",
        "            if cnt < input_length:\n",
        "                col.imshow(np.squeeze(ground_truth[0,cnt], axis=2))\n",
        "            else:\n",
        "                col.imshow(np.squeeze(predictions[0,cnt-input_length],axis=2))\n",
        "            col.axis('off')\n",
        "            cnt += 1    \n",
        "        \n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxmF8BqYGlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_prediction([90], plot_gt = True, use_own_predictions=True, show_label=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtFvJt-6YLc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_prediction([10], plot_gt = True, use_own_predictions=False, show_label=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdIQRzY2YMnP",
        "colab_type": "text"
      },
      "source": [
        "**END**"
      ]
    }
  ]
}