{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Small_UNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZ5vMwZ0hXnEAfx+POg4bZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsarm78/cs230Project/blob/master/models/model3_unet/Small_UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4oWjgDfdbZ-",
        "colab_type": "text"
      },
      "source": [
        "**Nowcasting using U-Net architecture**\n",
        "\n",
        "The basic architecture is an encoder-decoder pair with skip connections to combine low-level feature maps with higher-level ones. \n",
        "\n",
        "Pros:\n",
        "*   Has good performance.\n",
        "*   Can work with less labeled data.\n",
        "*   Typically scaled invariant (can work with multiple input sizes) as there are no dense layers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqObDMUgdhRG",
        "colab_type": "code",
        "outputId": "77d4fb1c-4d87-4972-dbd1-b350babf7c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Lambda, Conv2DTranspose, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras import backend as K\n",
        "from scipy.ndimage.measurements import label\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6si55fsAhcM1",
        "colab_type": "text"
      },
      "source": [
        "**Input Data & Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9AOG1jfhh5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_G-W9U9hiCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs3Tdu64hizY",
        "colab_type": "text"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb3zgUFjdp_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rows = 512\n",
        "img_cols = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FuP-UZUdiP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a small Unet\n",
        "# Smaller Unet defined so it fits in memory\n",
        "# Notice for donw/upsampling to work, image res must be divisible by 2^n, where n= maxpool layers\n",
        "\n",
        "# TODO:\n",
        "## Use: kernel_initializer='he_normal'\n",
        "##\n",
        "\n",
        "def get_small_unet():\n",
        "    inputs = Input((img_rows, img_cols, 1))\n",
        "    inputs_norm = Lambda(lambda x: x/127.5 - 1.)\n",
        "    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    #drop4 = Dropout(0.5)(conv4)   \n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)  ## If dropout change conv4->drop4  ## Four maxpool convs for downsampling reducing resolution by half, for 4 times\n",
        "\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
        "    #drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    #Deconvolution & upsamples the image back to its original resolution.\n",
        "    up6 = concatenate([Conv2DTranspose(64, kernel_size=(\n",
        "        2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(32, kernel_size=(\n",
        "        2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(16, kernel_size=(\n",
        "        2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(8, kernel_size=(\n",
        "        2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Conv2D(16, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(16, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='linear')(conv9)  #not Sigmoid as it will give Segmentation\n",
        "    output = conv10\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgv0UOZsdlie",
        "colab_type": "code",
        "outputId": "d0b44515-e53f-4d9b-f506-dfb9978b3c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "model = get_small_unet()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5UDH3R2gQQQ",
        "colab_type": "text"
      },
      "source": [
        "**Use DICE coefficient**:\n",
        "\n",
        "Dice is a measure of overlap between two samples. It ranges from 0 to 1 , where a Dice coefficient of 1 denotes perfect and complete overlap. \n",
        "The Dice coefficient can be calculated as:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "where |Aâˆ©B| represents the common elements between sets A and B, and |A| represents the number of elements in set A (and likewise for set B)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7OiC4EwdniU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define DICE \n",
        "def smooth_dice_coeff(smooth=1.):\n",
        "\n",
        "    smooth = float(smooth)\n",
        "\n",
        "    # IOU or dice coeff calculation\n",
        "    def IOU_calc(y_true, y_pred):\n",
        "            y_true_f = K.flatten(y_true)\n",
        "            y_pred_f = K.flatten(y_pred)\n",
        "            intersection = K.sum(y_true_f * y_pred_f)\n",
        "\n",
        "            return 2*(intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "    def IOU_calc_loss(y_true, y_pred):\n",
        "        return -IOU_calc(y_true, y_pred)\n",
        "    return IOU_calc, IOU_calc_loss\n",
        "\n",
        "IOU_calc, IOU_calc_loss = smooth_dice_coeff(0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eojQ5Ufhd8Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam(lr=1e-4), loss=IOU_calc_loss, metrics=[IOU_calc])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utuWwPGYd8cR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=10, epochs=50, verbose=1, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3Hmk8cqeAHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZndKe307eCAe",
        "colab_type": "text"
      },
      "source": [
        "**Performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmLUPYjVeFhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(model.history.history['loss'], label='Train loss')\n",
        "plt.plot(model.history.history['val_loss'], label='Val loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXrqHVfueI9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(20, 5))\n",
        "plt.plot(model.history.history['IOU_calc'], label='Train IOU')\n",
        "plt.plot(model.history.history['val_IOU_calc'], label='Val IOU')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('IOU')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqECQKpreLjf",
        "colab_type": "text"
      },
      "source": [
        "**Prediction on Test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9NFkOjieJ0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "\n",
        "def predict_evaluation(pred, image, label):\n",
        "    '''\n",
        "    '''\n",
        "    # transform gray image to rgb\n",
        "    img = np.array(image, np.uint8)\n",
        "    rgb_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    # scale pred and mask's pixel range to 0~255\n",
        "    im_label = np.array(255*label, dtype=np.uint8)\n",
        "    im_pred = np.array(255*pred, dtype=np.uint8)\n",
        "\n",
        "    # transform both of them to rgb\n",
        "    rgb_label = cv2.cvtColor(im_label, cv2.COLOR_GRAY2RGB)\n",
        "    rgb_pred = cv2.cvtColor(im_pred, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    rgb_label[:, :, 1:3] = 0*rgb_label[:, :, 1:2]\n",
        "    rgb_pred[:, :, 0] = 0*rgb_pred[:, :, 0]\n",
        "    rgb_pred[:, :, 2] = 0*rgb_pred[:, :, 2]\n",
        "\n",
        "    img_pred = cv2.addWeighted(rgb_img, 1, rgb_pred, 0.3, 0)\n",
        "    img_label = cv2.addWeighted(rgb_img, 1, rgb_label, 0.3, 0)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(rgb_img)\n",
        "    plt.title('Original image')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(img_pred)\n",
        "    plt.title('Prediction')\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(img_label)\n",
        "    plt.title('Ground truth')\n",
        "    plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck4RqCr1eSXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_evaluation(predict[0,:,:,0], X_test[0,:,:,0], y_test[0,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrFb_PRKeUwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_evaluation(predict[1,:,:,0], X_test[1,:,:,0], y_test[1,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25VF_fZOebUj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_evaluation(predict[2,:,:,0], X_test[2,:,:,0], y_test[2,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhHFlibLedeY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_evaluation(predict[3,:,:,0], X_test[3,:,:,0], y_test[3,:,:,0])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}