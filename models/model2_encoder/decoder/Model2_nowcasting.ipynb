{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model2_nowcasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsarm78/cs230Project/blob/master/models/model2_encoder/decoder/Model2_nowcasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSL5SRg5P_Aa",
        "colab_type": "code",
        "outputId": "d03ab210-aaf5-4274-d70a-9bf1498afbf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!git clone https://github.com/gsarm78/cs230Project.git\n",
        "print(\"[INFO] Git repo cloned\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'cs230Project' already exists and is not an empty directory.\n",
            "[INFO] Git repo cloned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyHbfK8vQBOq",
        "colab_type": "code",
        "outputId": "5c539667-b9ca-4bb2-a222-50f0b140f04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "import os\n",
        "import time\n",
        "import pylab as plt\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow.compat.v1.keras as keras\n",
        "import tensorflow.compat.v1.keras.backend\n",
        "from tensorflow.compat.v1.keras.models import Sequential, Model, load_model, model_from_json\n",
        "from tensorflow.compat.v1.keras.layers import Input, Add, Conv2D, Conv3D, Conv2DTranspose, Concatenate, TimeDistributed, BatchNormalization, ConvLSTM2D, BatchNormalization, LeakyReLU, MaxPooling2D, UpSampling2D, TimeDistributed, MaxPooling2D, UpSampling2D, Lambda, Dropout, Flatten, Reshape\n",
        "from tensorflow.compat.v1.keras.optimizers import *\n",
        "from tensorflow.compat.v1.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.compat.v1.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.compat.v1.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "import logging\n",
        "logging.getLogger('tensorflow').setLevel(logging.DEBUG)\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  ### NO WARNINGS!\n",
        "tf.__version__\n",
        "print(\"[INFO] Imports loaded.\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] Imports loaded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l70MRFFHQHcA",
        "colab_type": "code",
        "outputId": "20d2e198-957c-4336-96dc-4018f9990290",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# DATA LOADING AND PROCESSING INTO NUMPY ARRAY\n",
        "\n",
        "IMAGE_PATH = '/content/cs230Project/samples'\n",
        "\n",
        "\n",
        "WIDTH = 64\n",
        "HEIGHT = 64\n",
        "IMG_SEQUENCE = np.array([])\n",
        "INPUT_SEQUENCE = np.array([])\n",
        "NEXT_SEQUENCE = np.array([])\n",
        "NUMBER = 0\n",
        "\n",
        "def image_initialize(image):\n",
        "    picture = Image.open(image)\n",
        "    #picture = picture.crop((243, 176, 1428, 1280))\n",
        "    picture = picture.resize((WIDTH, HEIGHT), Image.ANTIALIAS)\n",
        "    picture = picture.convert('L')\n",
        "    data = np.array(picture.getdata()).reshape(WIDTH, HEIGHT, 1)\n",
        "    return data\n",
        "\n",
        "for file in os.listdir(IMAGE_PATH):\n",
        "    image_array = image_initialize(os.path.join(IMAGE_PATH, file))\n",
        "    IMG_SEQUENCE = np.append(IMG_SEQUENCE, image_array)\n",
        "    NUMBER += 1\n",
        "\n",
        "IMG_SEQUENCE = IMG_SEQUENCE.reshape(NUMBER, WIDTH * HEIGHT)\n",
        "print(IMG_SEQUENCE.shape)\n",
        "\n",
        "for i in IMG_SEQUENCE:\n",
        "    for j in range(int(len(i))):\n",
        "        if i[j] < 50:\n",
        "            i[j] = 0\n",
        "\n",
        "#np.savez('/content/cs230Project/data/images_sequence_array.npz', sequence_array=IMG_SEQUENCE) # test\n",
        "np.savez('/content/cs230Project/data/images_sequence_array.npz', sequence_array=IMG_SEQUENCE) # original\n",
        "print('[INFO] Data (images) saved as numpy compressed array')\n",
        "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(80, 4096)\n",
            "[INFO] Data (images) saved as numpy compressed array\n",
            "2020-03-15 19:19:09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPRrWJ1nUCe5",
        "colab_type": "code",
        "outputId": "4723e018-be6b-4128-ec9d-a2a34ad2d370",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# LOADING OF NUMPY ARRAY INTO SEQUENCES #\n",
        "#########################################\n",
        "\n",
        "FRAMES = 20 #frames to process\n",
        "\n",
        "IMG_SEQUENCE = np.load('/content/cs230Project/data/images_sequence_array.npz')['sequence_array']  # load array\n",
        "print('[INFO] Image Sequence Data loaded.')\n",
        "#print('[INFO]', IMG_SEQUENCE.shaoe)\n",
        "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime()))\n",
        "\n",
        "\n",
        "\n",
        "# Number of input images in the sequence\n",
        "NUMBER = len(IMG_SEQUENCE)\n",
        "\n",
        "IMG_SEQUENCE = IMG_SEQUENCE.reshape(NUMBER, WIDTH, HEIGHT, 1)\n",
        "print(IMG_SEQUENCE.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Image Sequence Data loaded.\n",
            "2020-03-15 19:19:09\n",
            "(80, 64, 64, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkgKGeRUyaU",
        "colab_type": "code",
        "outputId": "0c3db181-af59-431f-8c63-f29c1b85f620",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "INPUT_SEQUENCE = np.zeros((NUMBER-FRAMES, FRAMES, WIDTH, HEIGHT, 1), dtype=float)\n",
        "NEXT_SEQUENCE = np.zeros((NUMBER-FRAMES, FRAMES, WIDTH, HEIGHT, 1), dtype=float)\n",
        "\n",
        "\n",
        "\n",
        "#######\n",
        "# report pixel means and standard deviations\n",
        "#print('[INFO] IMG_SEQUENCE Statistics train=%.3f (%.3f)' % (IMG_SEQUENCE.mean(), IMG_SEQUENCE.std()))\n",
        "#mean substraction\n",
        "#IMG_SEQUENCE -=np.mean(IMG_SEQUENCE)\n",
        "#print('[INFO] IMG_SEQUENCE after Zero centred train=%.3f (%.3f)' % (IMG_SEQUENCE.mean(), IMG_SEQUENCE.std()))\n",
        "#IMG_SEQUENCE /= np.std(IMG_SEQUENCE)\n",
        "#print('normalised train=%.3f (%.3f)' % (IMG_SEQUENCE.mean(), IMG_SEQUENCE.std()))\n",
        "########\n",
        "\n",
        "for i in range(FRAMES):\n",
        "    #print(i)\n",
        "    INPUT_SEQUENCE[:, i, :, :, :] = IMG_SEQUENCE[i:i+NUMBER-FRAMES]\n",
        "    NEXT_SEQUENCE[:, i, :, :, :] = IMG_SEQUENCE[i+1:i+NUMBER-FRAMES+1]\n",
        "\n",
        "print('[INFO] InputSeq Statistics=%.3f (%.3f)' % (INPUT_SEQUENCE.mean(), INPUT_SEQUENCE.std()))\n",
        "print('[INFO] NextSeq Statistics=%.3f (%.3f)' % (NEXT_SEQUENCE.mean(), NEXT_SEQUENCE.std()))\n",
        "\n",
        "print(INPUT_SEQUENCE.shape)\n",
        "print(NEXT_SEQUENCE.shape) \n",
        "print(\"[INFO] Input sequence ready\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] InputSeq Statistics=8.954 (31.579)\n",
            "[INFO] NextSeq Statistics=8.952 (31.577)\n",
            "(60, 20, 64, 64, 1)\n",
            "(60, 20, 64, 64, 1)\n",
            "[INFO] Input sequence ready\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1tsYtMJQNfZ",
        "colab_type": "code",
        "outputId": "2e7489e8-2fea-4775-9812-e6956ec67712",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "'''\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow.compat.v1.keras as keras\n",
        "\n",
        "from tensorflow.compat.v1.keras.models import Model, load_model\n",
        "from tensorflow.compat.v1.keras.layers import Input, Conv2D, ConvLSTM2D, Dense, Conv2DTranspose, SeparableConv2D\n",
        "from tensorflow.compat.v1.keras.layers import MaxPooling2D, UpSampling2D, Lambda, Dropout, Flatten, Reshape\n",
        "from tensorflow.compat.v1.keras.layers import TimeDistributed, BatchNormalization, Concatenate\n",
        "from tensorflow.compat.v1.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "tf.__version__\n",
        "'''"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport time\\nfrom pathlib import Path\\n\\nimport tensorflow.compat.v1 as tf\\nimport tensorflow.compat.v1.keras as keras\\n\\nfrom tensorflow.compat.v1.keras.models import Model, load_model\\nfrom tensorflow.compat.v1.keras.layers import Input, Conv2D, ConvLSTM2D, Dense, Conv2DTranspose, SeparableConv2D\\nfrom tensorflow.compat.v1.keras.layers import MaxPooling2D, UpSampling2D, Lambda, Dropout, Flatten, Reshape\\nfrom tensorflow.compat.v1.keras.layers import TimeDistributed, BatchNormalization, Concatenate\\nfrom tensorflow.compat.v1.keras.callbacks import ModelCheckpoint\\n\\ntf.__version__\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajJ-7CY1Qhdd",
        "colab_type": "code",
        "outputId": "717b775f-657b-4d11-c665-c593e84066d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Bring dataset in shape\n",
        "xs = INPUT_SEQUENCE\n",
        "xs = xs.astype(np.float32)\n",
        "xs = xs / np.max(xs)\n",
        "#xs = np.swapaxes(xs, 0, 1)  # swap frames and observations so [obs, frames, height, width, channels]\n",
        "#xs = np.expand_dims(xs, -1) #Add channel dimension\n",
        "print(f\"Dataset shape: {xs.shape}\")\n",
        "print('[INFO] InputSeq Statistics=%.3f (%.3f)' % (xs.mean(), xs.std()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset shape: (60, 20, 64, 64, 1)\n",
            "[INFO] InputSeq Statistics=0.042 (0.148)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T_tDGeNQnmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Motion Diff Input for Motion Encoder\n",
        "def motion_diff(x):\n",
        "    seqLen = len(x[0])\n",
        "    return np.asarray([[x[n][i]-x[n][i-1] for i in range(1,seqLen)] for n in range(len(x))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1BsG7tFROn9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "end = 50  #8000\n",
        "seqLen = 10\n",
        "x_dim, y_dim, c_dim = 64, 64, 1\n",
        "fs = (5,5)  # filter size for convolutional kernels\n",
        "nk = 128     # number of kernels for conv layers #48 \n",
        "nd = 2048    # number of neurons in dense layers #192"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P8le4ZcmfWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smooth=1e-9\n",
        "  #Additional metrics: SSIM, PSNR, POD, FAR\n",
        "def ssim(x, y, max_val=1.0):\n",
        "  return tf.image.ssim(x, y, max_val)\n",
        "\n",
        "def psnr(x, y, max_val=1.0):\n",
        "  return tf.image.psnr(x, y, max_val)\n",
        "\n",
        "  #recall\n",
        "def POD(x, y):\n",
        "  y_pos = keras.backend.clip(x, 0, 1)\n",
        "  y_pred_pos = keras.backend.clip(y, 0, 1)\n",
        "  y_pred_neg = 1 - y_pred_pos\n",
        "  tp = keras.backend.sum(y_pos * y_pred_pos)\n",
        "  fn = keras.backend.sum(y_pos * y_pred_neg)\n",
        "  return (tp+smooth)/(tp+fn+smooth)\n",
        "\n",
        "def FAR(x, y):\n",
        "  y_pred_pos = keras.backend.clip(y, 0, 1)\n",
        "  y_pos = keras.backend.clip(x, 0, 1)\n",
        "  y_neg = 1 - y_pos\n",
        "  tp = keras.backend.sum(y_pos * y_pred_pos)\n",
        "  fp = keras.backend.sum(y_neg * y_pred_pos)\n",
        "  return (fp)/(tp+fp+smooth)\n",
        "\n",
        "metrics = ['accuracy', ssim, psnr, POD, FAR]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZcwVnS2Rd99",
        "colab_type": "code",
        "outputId": "9cc05eac-f216-4f71-872f-7bc2265642f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Inputs\n",
        "dtype='float32'\n",
        "contentInput = Input(shape=(x_dim, y_dim, c_dim), name='content_input', dtype=dtype)\n",
        "motionInput = Input(shape=(None, x_dim, y_dim, c_dim), name='motion_input', dtype=dtype)\n",
        "\n",
        "# Content Encoder\n",
        "x = Conv2D(nk, fs, activation='relu', padding='same', name='content_conv_1')(contentInput)\n",
        "x = Conv2D(nk, fs, activation='relu', padding='same', name='content_conv_new1')(x) #new\n",
        "x = MaxPooling2D((2,2), name='content_pool_1')(x)\n",
        "#x = BatchNormalization()(x) #new\n",
        "x = Conv2D(nk*2, fs, activation='relu', padding='same', name='content_conv_2')(x)\n",
        "x = Conv2D(nk*2, fs, activation='relu', padding='same', name='content_conv_new2')(x) #new\n",
        "x = MaxPooling2D((2,2), name='content_pool_2')(x)\n",
        "#x = Dropout(rate=0.5, name='dropout')(x)\n",
        "#x = BatchNormalization()(x)#new\n",
        "x = Conv2D(nk*4, fs, activation='relu', padding='same', name='content_conv_3')(x)\n",
        "x = Conv2D(nk*4, fs, activation='relu', padding='same', name='content_conv_new3')(x) #new\n",
        "x = Conv2D(nk*4, fs, activation='relu', padding='same', name='content_conv_new3-2')(x) #new\n",
        "contentEnc = MaxPooling2D((2,2), name='content_pool_3')(x)\n",
        "#x = BatchNormalization()(x)#new\n",
        "#x = Flatten()(x)\n",
        "#contentEnc = Dense(nd*4, activation='relu', name='content_latent')(x)\n",
        "\n",
        "# Motion Encoder\n",
        "# Layer 1\n",
        "tcnv1 = TimeDistributed(Conv2D(nk, (5,5), activation='relu', padding='same'), name='motion_conv_1')(motionInput) \n",
        "x = TimeDistributed(MaxPooling2D((2,2)), name='motion_pool_1')(tcnv1) #original (2,2)\n",
        "# Layer 2\n",
        "tcnv2 = TimeDistributed(Conv2D(nk, (5,5), activation='relu', padding='same'), name='motion_conv_2')(x)\n",
        "x = TimeDistributed(MaxPooling2D((2,2)), name='motion_pool_2')(tcnv2)\n",
        "# Layer 3\n",
        "tcnv3 = TimeDistributed(Conv2D(nk, (7,7), activation='relu', padding='same'), name='motion_conv_3')(x)\n",
        "x = TimeDistributed(MaxPooling2D((2,2)), name='motion_pool_3')(tcnv3)\n",
        "# Layer 4\n",
        "motionEnc = ConvLSTM2D(nk*8, (8,8), activation='relu', padding='same', return_sequences=False, dropout=0.4, recurrent_dropout=0.4, name='motion_lstm', dtype=dtype)(x)\n",
        "#x = Flatten()(x)\n",
        "#motionEnc = Dense(nd*4, activation='relu', name='motion_latent')(x) #relu #sigmoid before\n",
        "\n",
        "# Combination\n",
        "x = Concatenate(name='concat_layer')([contentEnc, motionEnc])  #contentEnc, motionEnc\n",
        "x = Conv2D(nk*4, (3, 3), activation='relu', padding='same', name='comb_conv_1')(x)\n",
        "x = Conv2D(nk*2, (3, 3), activation='relu', padding='same', name='comb_conv_new1')(x) #new\n",
        "combined = Conv2D(nk*4, (3, 3), activation='relu', padding='same', name='comb_conv_new1-2')(x)\n",
        "\n",
        "# Residuals\n",
        "res3 = Lambda(lambda x: x[:,-1])(tcnv3)\n",
        "res2 = Lambda(lambda x: x[:,-1])(tcnv2)\n",
        "res1 = Lambda(lambda x: x[:,-1])(tcnv1)\n",
        "\n",
        "# Decoder\n",
        "x = UpSampling2D((2,2), name='decoder_upsample_1')(combined)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_1')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_new1')(x) #new\n",
        "x = Conv2DTranspose(nk*2, fs, activation='relu', padding='same', name='decoder_conv_new1-2')(x) #new\n",
        "\n",
        "x = Concatenate()([x, res3]) #res3\n",
        "x = UpSampling2D((2,2), name='decoder_upsample_2')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_2')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_new2')(x) #new\n",
        "\n",
        "x = Concatenate()([x, res2])\n",
        "x = UpSampling2D((2,2), name='decoder_upsample_3')(x)\n",
        "x = Conv2DTranspose(nk*4, fs, activation='relu', padding='same', name='decoder_conv_3')(x)\n",
        "x = Concatenate()([x, res1]) #res1\n",
        "#x = BatchNormalization()(x)\n",
        "predictions = Conv2DTranspose(1, fs, activation='tanh', padding='same', name='prediction')(x) #sigmoid original\n",
        "\n",
        "#custom loss function\n",
        "def weight_loss(y_true,y_pred):\n",
        "    pw = 2\n",
        "    ytrue = keras.backend.flatten(y_true)\n",
        "    ypred = keras.backend.flatten(y_pred)\n",
        "    return tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=ypred,targets=ytrue,pos_weight=pw))\n",
        "\n",
        "\n",
        "# Create and compile model\n",
        "model = Model(inputs= [contentInput, motionInput], outputs=predictions)\n",
        "\n",
        "optim = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "model.compile(loss='mse', optimizer=optim, metrics=metrics) #mse \n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I56D38BRh20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Visualise Model Topology and save to file (model.png)\n",
        "#from keras.utils import plot_model\n",
        "#plot_model(model, show_shapes=True, to_file='/model.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6BNVohsRkt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data\n",
        "train_x = [xs[:end,seqLen-2], motion_diff(xs[:end,:seqLen-1])]  #list\n",
        "\n",
        "# train_x = motion_diff(xs[:end,:seqLen-1])\n",
        "\n",
        "train_y = xs[:end,seqLen-1]\n",
        "\n",
        "val_x   = [xs[end:,seqLen-2], motion_diff(xs[end:,:seqLen-1])]\n",
        "\n",
        "# val_x   = motion_diff(xs[end:,:seqLen-1])\n",
        "\n",
        "val_y   = xs[end:,seqLen-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WZFupfBRoHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define Class to track performance (loss) hisrory\n",
        "class LossHistory(keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, start_new_on_train_begin):\n",
        "        self.start_new_on_train_begin = start_new_on_train_begin\n",
        "        self.batches = []\n",
        "        self.epochs = {'train':[], 'val':[]}\n",
        "    \n",
        "    def on_train_begin(self, logs={}):\n",
        "        if self.start_new_on_train_begin:\n",
        "            self.batches = []\n",
        "            self.epochs = {'train':[], 'val':[]}\n",
        "\n",
        "    def copy_from(self, different_loss_history):\n",
        "        self.batches = different_loss_history.batches\n",
        "        self.epochs = different_loss_history.epochs\n",
        "            \n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        self.batches.append(logs.get('loss'))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.epochs['train'].append(logs.get('loss'))\n",
        "        self.epochs['val'].append(logs.get('val_loss'))\n",
        "loss_history = LossHistory(start_new_on_train_begin=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md_PGixSRsha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d7d564fa-4c63-4134-c105-874e7ffa8270"
      },
      "source": [
        "#Training Hyperparameters\n",
        "batch_size = 2\n",
        "n_epochs = 25\n",
        "\n",
        "history = model.fit(train_x, train_y, batch_size=batch_size, \n",
        "                    epochs=n_epochs, validation_data=(val_x, val_y),\n",
        "                    callbacks=[loss_history], use_multiprocessing=True) # Add shuffle=True"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 50 samples, validate on 10 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4ZxsCG8TiMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save model\n",
        "model.save('Model2_Nowcasting_(CoderDecoder_Arch).h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sa6I_4FX1bE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot Training Loss vs. Validation Loss\n",
        "plt.plot(loss_history.epochs['train'][2:], label='Training Loss')\n",
        "plt.plot(loss_history.epochs['val'][2:], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw8VdtImX6ed",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "performance_history = {\n",
        "    'batches':loss_history.batches,\n",
        "    'epochs':loss_history.epochs\n",
        "    }\n",
        "with open('model_loss_history.txt', 'w') as f:\n",
        "    print(performance_history, file=f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jme08yIX9eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment to \n",
        "# Load model from storage\n",
        "\n",
        "#model_dir = '/'\n",
        "#model = load_model(Path(model_dir, 'Model2_Nowcasting_(CoderDecoder_Arch).h5'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uoZZEyjYDRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_prediction(seq_idx, plot_gt=False, use_own_predictions=False, show_label=True):\n",
        "    for i, which in enumerate(seq_idx):\n",
        "\n",
        "        if show_label: print(f\"({i+1}) : {which}\")\n",
        "\n",
        "        input_length = 10 # length of input sequence\n",
        "        prediction_length = 10 # length of prediction\n",
        "        ground_truth = xs[which:which+1] # ground truth sequence\n",
        "\n",
        "\n",
        "        if use_own_predictions:\n",
        "            print(\"Use_own_prediction = True\")\n",
        "            pred = xs[which:which+1,input_length-1] # current frame, (1, 64, 64, 1)\n",
        "            print(pred.shape)\n",
        "            input_seq = ground_truth[:,0:input_length] # input sequence (first <inputLen> frames)   ,  (1, 10, 64, 64, 1)\n",
        "            print(input_seq.shape)\n",
        "            for i in range(input_length):\n",
        "                # Model predicts next frame\n",
        "                pred = model.predict([pred, motion_diff(input_seq)]) # return shape: (1, 64, 64, 1)\n",
        "                # Cut first frame from sequence\n",
        "                input_seq = np.squeeze(input_seq, axis=0)\n",
        "                input_seq = input_seq[1:]\n",
        "                # Append predicted frame to sequence\n",
        "                input_seq = np.append(input_seq, pred, axis=0)\n",
        "                input_seq = np.array([input_seq]) \n",
        "            predictions = input_seq\n",
        "        \n",
        "        else:\n",
        "            # Use ground truth in each time step as input\n",
        "            print(\"Use_own_prediction = False\")\n",
        "            print(\"Use Ground truth in each time step as input\")\n",
        "            predictions = []\n",
        "            for i in range(prediction_length):\n",
        "                input_seq = ground_truth[:, i:input_length+i]\n",
        "                prediction = model.predict([input_seq[:,-1], motion_diff(input_seq)])\n",
        "                predictions.append(prediction[0])\n",
        "            predictions = np.array([predictions])\n",
        "        \n",
        "        figures=(input_length*2, 1)\n",
        "        #figures=(input_length+prediction_length, 1)\n",
        "        \n",
        "        # Plot the ground truth sequence\n",
        "        if plot_gt:\n",
        "            fig,axs = plt.subplots(1, input_length+prediction_length, figsize=figures); cnt=0\n",
        "            for col in axs:\n",
        "                col.imshow(np.squeeze(ground_truth[0,cnt], axis=2))\n",
        "                col.axis('off')\n",
        "                cnt += 1   \n",
        "\n",
        "\n",
        "        # Plot the input and predicted sequence\n",
        "        fig,axs = plt.subplots(1, input_length+prediction_length, figsize=figures); cnt=0\n",
        "        for col in axs:\n",
        "            if cnt < input_length:\n",
        "                col.imshow(np.squeeze(ground_truth[0,cnt], axis=2))\n",
        "            else:\n",
        "                col.imshow(np.squeeze(predictions[0,cnt-input_length],axis=2))\n",
        "            col.axis('off')\n",
        "            cnt += 1    \n",
        "        \n",
        "        plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSxmF8BqYGlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_prediction([90], plot_gt = True, use_own_predictions=True, show_label=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtFvJt-6YLc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_prediction([10], plot_gt = True, use_own_predictions=False, show_label=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdIQRzY2YMnP",
        "colab_type": "text"
      },
      "source": [
        "**END**"
      ]
    }
  ]
}